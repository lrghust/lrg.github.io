






<!doctype html>
<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <meta name="author" content="Ruiguang Li">
  
  
  
  
    <meta name="description" content="Paper: Fast R-CNN
R-CNNSteps
Object Detection
Object Recognition

Drawbacks
Multi-stage
Expensive in space and time
Slow: no sharing computation

Two Challenges in Object Detection
Numerous proposa...">
  
  <title>Note_Fast R-CNN [ Ruiguang Li ]</title>
  
  
    <link rel="shortcut icon" href="https://ruigli.files.wordpress.com/2018/04/head-e1524538855144.png">
  
  
  <link rel="stylesheet" href="/css/random.css">
<link rel="stylesheet" href="/css/vegas.min.css">
<link rel="stylesheet" href="/css/highlight-railscasts.css">
<link rel="stylesheet" href="/css/jquery.fancybox.css">
<link rel="stylesheet" href="/css/iconfont/iconfont.css">
<link rel="stylesheet" href="/css/jquery.fancybox-thumbs.css">
<link rel="stylesheet" href="/css/plyr.css">
  
</head>

<body>
<div class="side-navigate hide-area">
  
    <div class="item prev">
      <a href="/2017/02/13/seq-nms/">
        <div class="item-icon"></div>
      </a>
      <div class="item-title">
        Note_SEQ-NMS for Video Object Detection
      </div>
    </div>
  
  
    <div class="item next">
      <a href="/2017/01/20/imagenet-classification-with-deep-convolutional-neural-networks/">
        <div class="item-icon"></div>
      </a>
      <div class="item-title">
        Note_Imagenet Classification with Deep Convolutional Neural Networks
      </div>
    </div>
  
</div>
<div id="outer-container" class="hide-area">
<div id="container">
  <div id="menu-outer" class="slide-down">
    <div id="menu-inner">
      <div id="brand">
        
        <a onClick="openUserCard()">
          <img id="avatar" src="https://ruigli.files.wordpress.com/2018/04/head-e1524538855144.png"/>
          <div id="homelink">Ruiguang Li</div>
        </a>
      </div>
      <div id="menu-list">
        <ul>
        
        
          
            <li>
          
            <a href="http://www.ruiguangli.com">Home</a>
            
          </li>
        
          
            <li>
          
            <a href="https://blog.ruiguangli.com">Blog</a>
            
          </li>
        
          
            <li>
          
            <a href="https://sites.google.com/view/ruiguangli">About</a>
            
          </li>
        
          
            <li>
          
            <a href="https://github.com/lrghust">Github</a>
            
          </li>
        
        </ul>
      </div>
      <div id="show-menu">
        <button>Menu</button>
      </div>
    </div>
  </div>

  <div id="content-outer">
    <div id="content-inner">
      
      
  <article id="post">
    <h1>Note_Fast R-CNN</h1>
    <p class="page-title-sub">
      <span id = "post-title-date">Created at 2017-01-20</span>
      
        <span id = "post-title-updated">Updated at 2018-02-25</span>
      
      
      <span id = "post-title-categories">Category
      
      
        
        
        <a href="/categories/CNN/">CNN</a>
      
      </span>
      
      
      <span id = "post-title-tags">
      Tag
      
      
        
        
        <a href="/tags/Note/">Note</a>
      
        
          /
        
        
        <a href="/tags/Fast-R-CNN/">Fast R-CNN</a>
      
        
          /
        
        
        <a href="/tags/Deep-Learning/">Deep Learning</a>
      
        
          /
        
        
        <a href="/tags/Machine-Learning/">Machine Learning</a>
      
      </span>
      
    </p>
    
    <p>Paper: Fast R-CNN</p>
<h2 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a>R-CNN</h2><h3 id="Steps"><a href="#Steps" class="headerlink" title="Steps"></a>Steps</h3><ol>
<li>Object Detection</li>
<li>Object Recognition</li>
</ol>
<h3 id="Drawbacks"><a href="#Drawbacks" class="headerlink" title="Drawbacks"></a>Drawbacks</h3><ol>
<li>Multi-stage</li>
<li>Expensive in space and time</li>
<li>Slow: no sharing computation</li>
</ol>
<h3 id="Two-Challenges-in-Object-Detection"><a href="#Two-Challenges-in-Object-Detection" class="headerlink" title="Two Challenges in Object Detection"></a>Two Challenges in Object Detection</h3><ol>
<li>Numerous proposals</li>
<li>Rough localization needs to be refined</li>
</ol>
<h2 id="This-paper"><a href="#This-paper" class="headerlink" title="This paper:"></a>This paper:</h2><ul>
<li>A single-stage training algorithm: classify proposals and refine locations</li>
</ul>
<h2 id="SPPnet"><a href="#SPPnet" class="headerlink" title="SPPnet"></a>SPPnet</h2><h3 id="Drawbacks-1"><a href="#Drawbacks-1" class="headerlink" title="Drawbacks"></a>Drawbacks</h3><ol>
<li>Multi-stage pipeline: extracting features -&gt; fine-tuning a network with log loss -&gt; training SVMs -&gt; fitting bounding-box regressors</li>
<li>Cannot update convolutional layers, limits the accuracy of very deep networks</li>
</ol>
<h2 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a>Fast R-CNN</h2><h3 id="Advantages"><a href="#Advantages" class="headerlink" title="Advantages"></a>Advantages</h3><ol>
<li>Higher detection quality</li>
<li>Single-stage,multi-task loss</li>
<li>Update all network layers</li>
<li>No disk storage</li>
</ol>
<h3 id="Architecture"><a href="#Architecture" class="headerlink" title="Architecture"></a>Architecture</h3><ol>
<li>Input: Take an entire image and object proposals as input</li>
<li>A feature map: by processing the whole image with several conv layers and max pooling layers</li>
<li>Feature vector: fixed-length, extracted from the feature map by a RoI pooling layer for each object proposal</li>
<li>Two output layers: each feature vector fed into FCs, branch into two output layers:<ul>
<li>K classes softmax layer + a catch-all class</li>
<li>Four-tuple, refined bounding-box position for one of the K classes</li>
</ul>
</li>
</ol>
<h4 id="RoI-pooling-layer"><a href="#RoI-pooling-layer" class="headerlink" title="RoI pooling layer"></a>RoI pooling layer</h4><p>Divide the h<em> w RoI window into an H</em> W grid, size of sub-window is h/H*w/W, do max-pooling in each sub-window</p>
<h4 id="Transform-a-pre-trained-network-to-a-Fast-R-CNN"><a href="#Transform-a-pre-trained-network-to-a-Fast-R-CNN" class="headerlink" title="Transform a pre-trained network to a Fast R-CNN"></a>Transform a pre-trained network to a Fast R-CNN</h4><ol>
<li>Replace the last max-pooling layer by RoI pooling layer</li>
<li>Replace the last fully connected layer and softmax by the two output layers mentioned above(K+1 softmax and bounding-box regressors)</li>
<li>Replace the input by a whole image and RoIs</li>
</ol>
<h4 id="Multi-task-loss"><a href="#Multi-task-loss" class="headerlink" title="Multi-task loss"></a>Multi-task loss</h4><p>Note two outputs as classification and location</p>
<ul>
<li>classification: p=(p0,p1,…,pK), a discrete probability distribution over K+1 classes</li>
<li>location: tk=(txk,tyk,twk,thk), bounding-box regression offsets, for K classes</li>
</ul>
<p>Each training RoI is labeled: u - ground-truth class v - ground-truth bounding-box regression target</p>
<p><strong>Multi-task loss L:</strong><br><img src="/img/posts/multi-task-loss.png" alt="Multi-task loss"></p>
<pre><code>Lcls: log loss for u
lamda[]: Iverson function
Lloc(tu,v)=Sigma smoothL1(tiu-vi)
smoothL1(x)=0.5x^x, |x|&lt;1
            |x|-0.5, otherwise
</code></pre><h4 id="Mini-batch-sampling"><a href="#Mini-batch-sampling" class="headerlink" title="Mini-batch sampling"></a>Mini-batch sampling</h4><ul>
<li>size of mini-batch: R=128=2*64, consisting of N=2 images and 64 RoIs in each image</li>
<li>25% of RoIs have IoU over 0.5, foreground object class</li>
<li>remaining RoIs have IoU between 0.1 and 0.5, background, u=0</li>
<li>images are flipped horizontally with probability 0.5, aiming to data augmentation</li>
</ul>
<h4 id="Backward-function"><a href="#Backward-function" class="headerlink" title="Backward function"></a>Backward function</h4><p><img src="/img/posts/backward_function.png" alt="backward function"></p>
<pre><code>i* (r,j): the index of output by doing max-pooling on the j-th sub-
        window, the r-th RoI
</code></pre><ul>
<li>if i=i* (r,j), accumulate the partial derivative(with respect to yrj)</li>
</ul>
<h3 id="Scale-invariance"><a href="#Scale-invariance" class="headerlink" title="Scale invariance(?)"></a>Scale invariance(?)</h3><ol>
<li>brute force learning</li>
<li>image pyramids</li>
</ol>
<h2 id="Fast-R-CNN-Detection"><a href="#Fast-R-CNN-Detection" class="headerlink" title="Fast R-CNN Detection"></a>Fast R-CNN Detection</h2><ol>
<li>take an image(or an image pyramid) and a list of object proposals as input</li>
<li>run a forward pass to score</li>
<li>output: a class probability distribution and a set of predicted bounding box offsets</li>
<li>for each RoI r, using the probability as detection confidence for each class k, then perform non-maximum suppression</li>
</ol>
<h3 id="Trancated-SVD"><a href="#Trancated-SVD" class="headerlink" title="Trancated SVD"></a>Trancated SVD</h3><p><img src="/img/posts/Trancated_SVD.png" alt="Trancated SVD"></p>
<ul>
<li>Compress large fully connected layers by trancated SVD to accelerate</li>
<li>replace one fully connected layer corresponding to W by two fc layers, with matrix weight U and ΣtVT respectively</li>
</ul>
<h2 id="Design-Evaluation-experimentally"><a href="#Design-Evaluation-experimentally" class="headerlink" title="Design Evaluation(experimentally)"></a>Design Evaluation(experimentally)</h2><ol>
<li>Multi-task training improves the classification accuracy</li>
<li>Scale-invariance: Single scale processing offers the best tradeoff between the speed and accuracy</li>
<li>More-training data improve the detection accuracy. The paper doesn’t mention about the problem of saturating with the increasing of dataset.</li>
<li>Softmax introduce competetion between classes when scoring a RoI. Softmax slightly outperfoming SVM.</li>
<li>Proposals: there are two types of object detector:<ul>
<li>use a <strong>sparse</strong> set of proposals: improves Fast R-CNN accuracy</li>
<li>use a <strong>dense</strong> set of proposals</li>
</ul>
</li>
</ol>
<ul>
<li>Using selective search, the accuracy improves first and falls slightly soon with the increasing number of proposals</li>
<li>Using densely generated boxes, adding random dense boxes and using only dense boxes all decrease the detection quality</li>
</ul>
<h2 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h2><p>This paper proposes Fast R-CNN, a clean and fast update to RNN and SPPnet.<br>Furthermore, this paper finds that sparse set of proposals improves the detection quality than dense one by using Fast R-CNN. There may exists new ways to allow dense set to perform as well as sparse one, by which we can accelerate object detection and improve the accuracy.</p>

  </article>
  <div class="random-toc-area">
  <button class="btn-hide-toc btn-hide-toc-show" style="display: none" onclick="TOCToggle()">Show TOC</button>
  <button class="btn-hide-toc btn-hide-toc-hide" onclick="TOCToggle()">Hide TOC</button>
  <div class="random-toc">
    <h2>Table of Content</h2>
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#R-CNN"><span class="toc-text">R-CNN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Steps"><span class="toc-text">Steps</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Drawbacks"><span class="toc-text">Drawbacks</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Two-Challenges-in-Object-Detection"><span class="toc-text">Two Challenges in Object Detection</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#This-paper"><span class="toc-text">This paper:</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#SPPnet"><span class="toc-text">SPPnet</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Drawbacks-1"><span class="toc-text">Drawbacks</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Fast-R-CNN"><span class="toc-text">Fast R-CNN</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Advantages"><span class="toc-text">Advantages</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Architecture"><span class="toc-text">Architecture</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RoI-pooling-layer"><span class="toc-text">RoI pooling layer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Transform-a-pre-trained-network-to-a-Fast-R-CNN"><span class="toc-text">Transform a pre-trained network to a Fast R-CNN</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Multi-task-loss"><span class="toc-text">Multi-task loss</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Mini-batch-sampling"><span class="toc-text">Mini-batch sampling</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Backward-function"><span class="toc-text">Backward function</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Scale-invariance"><span class="toc-text">Scale invariance(?)</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Fast-R-CNN-Detection"><span class="toc-text">Fast R-CNN Detection</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Trancated-SVD"><span class="toc-text">Trancated SVD</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Design-Evaluation-experimentally"><span class="toc-text">Design Evaluation(experimentally)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conclusion"><span class="toc-text">Conclusion</span></a></li></ol>
  </div>
</div>

  
<nav id="pagination">
  
    <a href="/2017/02/13/seq-nms/" class="prev">&larr; Prev post Note_SEQ-NMS for Video Object Detection</a>
  

  

  
    <a href="/2017/01/20/imagenet-classification-with-deep-convolutional-neural-networks/" class="next">Next post Note_Imagenet Classification with Deep Convolutional Neural Networks &rarr;</a>
  
</nav>

  <!-- JiaThis Button BEGIN -->

<!-- JiaThis Button END -->


      
      
    </div>
  </div>

  <div id="bottom-outer">
    <div id="bottom-inner">
      Site by Ruiguang Li using
      <a href="http://hexo.io">Hexo</a> & <a href="https://github.com/stiekel/hexo-theme-random">Random</a>
      <br>
      
    </div>
  </div>
</div>

</div>


<div id="user-card">
  <div class="center-field">
    <img class="avatar" src="https://ruigli.files.wordpress.com/2018/04/head-e1524538855144.png">
    <p id="description">Welcome to my blog!</p>
    <ul class="social-icon">
  
  
    <li>
      <a href="https://github.com/lrghust">
        
          <i class="icon iconfont github">&#xe606;</i>
        
      </a>
    </li>
  
    <li>
      <a href="http://weibo.com/ruiguangli">
        
          <i class="icon iconfont weibo">&#xe602;</i>
        
      </a>
    </li>
  
    <li>
      <a href="https://twitter.com/liruiguang">
        
          <i class="icon iconfont twitter">&#xe600;</i>
        
      </a>
    </li>
  
    <li>
      <a href="https://www.facebook.com/imrgli">
        
          <i class="icon iconfont facebook">&#xe604;</i>
        
      </a>
    </li>
  
</ul>
  </div>
</div>


<div id="btn-view">Hide</div>

<script>
// is trigger analytics / tongji script
var isIgnoreHost = false;

if(window && window.location && window.location.host) {
  isIgnoreHost = ["localhost","127.0.0.1"].some(function(address){
    return 0 === window.location.host.indexOf(address);
  });
}

var isTriggerAnalytics = !( true && isIgnoreHost );

</script>




  
  
    <script src="/js/jquery-2.2.3.min.js"></script>
  
    <script src="/js/vegas.min.js"></script>
  
    <script src="/js/random.js"></script>
  
    <script src="/js/highlight.pack.js"></script>
  
    <script src="/js/jquery.mousewheel.pack.js"></script>
  
    <script src="/js/jquery.fancybox.pack.js"></script>
  
    <script src="/js/jquery.fancybox-thumbs.js"></script>
  
    <script src="/js/plyr.js"></script>
  

<script>

  // fancybox
  var backgroundImages = [];
  
  $('#post').each(function(i){
    $(this).find('img').each(function(){
      if ($(this).parent().hasClass('fancybox') || $(this).parent().hasClass('fancybox-thumb')) return;
      var alt = this.alt || this.title;
      if (alt) $(this).after('<span class="caption">' + alt + '</span>');
      $(this).wrap('<a href="' + this.src + '" title="' + alt + '" class="fancybox"></a>');
    });
    $(this).find('.fancybox').each(function(){
      $(this).attr('rel', 'post' + i);
    });
  });
  $(".fancybox").fancybox();

var vegasConfig = {"preload­Image":true,"transition":["slideLeft2","slideRight2","flash2"],"timer":true,"delay":5000,"shuffle":true,"count":28};
var unsplashConfig = {"gravity":"north"};
// is show background images
var turnoffBackgroundImage = false;



  turnoffBackgroundImage = true;


var backgroundColor = "34495E";

$(".fancybox-thumb").fancybox({
  prevEffect: 'none',
  nextEffect: 'none',
  helpers: {
    title: {
      type: 'outside'
    },
    thumbs: {
      width: 50,
      height: 50
    }
  }
});

// show video with plyr
$(".video-container iframe").each(function(i){
  var url = $(this).attr('src');
  var id = url.split('/').pop();
  var plyrContainer = document.createElement('div');
  plyrContainer.className = 'plyr';
  var plyrElement = document.createElement('div');
  plyrElement.dataset.videoId = id;
  switch(true) {
    case url.search('youtube.com') >= 0:
      plyrElement.dataset.type = 'youtube';
      break;
    case url.search('vimeo.com') >= 0:
      plyrElement.dataset.type = 'vimeo';
      break;
    default:
      return;
  };
  plyrContainer.appendChild(plyrElement);
  $(this).parent().html(plyrContainer);
});
plyr.setup('.plyr', {iconUrl: '/css/sprite.svg'});
</script>
</body>
</html>

